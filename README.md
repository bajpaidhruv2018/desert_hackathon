# ğŸœï¸ Offroad Environment Segmentation AI

> **Semantic segmentation model for autonomous offroad navigation in desert terrain.**
>
> Built for the **Startathon Desert Hackathon** â€” classifies every pixel of a terrain image into one of 10 environmental categories to enable safe autonomous offroading.

![Python](https://img.shields.io/badge/Python-3.8%2B-blue)
![PyTorch](https://img.shields.io/badge/PyTorch-2.x-ee4c2c)
![Streamlit](https://img.shields.io/badge/Streamlit-1.32-ff4b4b)
![License](https://img.shields.io/badge/License-MIT-green)

---

## ğŸ“¸ Sample Predictions

> Each row shows: **Input Image** | **Ground Truth** | **AI Prediction**

| | | |
|:-:|:-:|:-:|
| ![Result 0](final_submission_results/result_0.png) | ![Result 1](final_submission_results/result_1.png) | ![Result 2](final_submission_results/result_2.png) |
| ![Result 3](final_submission_results/result_3.png) | ![Result 4](final_submission_results/result_4.png) | |

---

## ğŸ§  Model Architecture

| Component | Details |
|-----------|---------|
| **Architecture** | U-Net |
| **Encoder** | ResNet-34 (ImageNet pretrained) |
| **Framework** | [segmentation-models-pytorch](https://github.com/qubvel/segmentation_models.pytorch) |
| **Input Resolution** | 512 Ã— 512 |
| **Output Classes** | 10 |
| **Loss Function** | CrossEntropy + Dice (hybrid) |
| **Optimizer** | Adam (LR: 1e-5 for fine-tuning) |
| **LR Scheduler** | Cosine Annealing |
| **Augmentation** | Horizontal flip, Vertical flip |

---

## ğŸ·ï¸ Terrain Classes

| Class ID | Raw Pixel Value | Class Name | Legend Color |
|:--------:|:---------------:|------------|:------------:|
| 0 | 100 | Trees | ğŸŸ© `#228B22` |
| 1 | 200 | Lush Bushes | ğŸŸ¢ `#9ACD32` |
| 2 | 300 | Dry Grass | ğŸŸ¨ `#DAA520` |
| 3 | 500 | Dry Bushes | ğŸŸ« `#8B4513` |
| 4 | 550 | Ground Clutter | â¬œ `#808080` |
| 5 | 600 | Flowers | ğŸ©· `#FF69B4` |
| 6 | 700 | Logs | ğŸŸ¤ `#A0522D` |
| 7 | 800 | Rocks | â¬› `#696969` |
| 8 | 7100 | Landscape | ğŸŸ§ `#F4A460` |
| 9 | 10000 | Sky | ğŸ”µ `#87CEEB` |

---

## ğŸ“Š Performance

### Overall Metrics

| Metric | Score |
|--------|------:|
| **Pixel Accuracy** | 87.78% |
| **Mean IoU** | 65.38% |

### Per-Class IoU (Intersection over Union)

| Class | IoU | Rating |
|-------|----:|:------:|
| Sky | 98.73% | ğŸŸ¢ Excellent |
| Trees | 87.63% | ğŸŸ¢ Excellent |
| Dry Grass | 70.37% | ğŸŸ¡ Good |
| Lush Bushes | 70.14% | ğŸŸ¡ Good |
| Landscape | 69.78% | ğŸŸ¡ Good |
| Flowers | 64.22% | ğŸŸ¡ Good |
| Logs | 56.21% | ğŸŸ  Fair |
| Dry Bushes | 48.93% | ğŸŸ  Fair |
| Rocks | 47.84% | ğŸŸ  Fair |
| Ground Clutter | 39.98% | ğŸ”´ Needs Work |

> **Note:** Small / rare objects (Logs, Rocks, Ground Clutter) are harder to detect. The hybrid CrossEntropy + Dice loss was specifically added to improve these classes.

### Confusion Matrix

![Confusion Matrix](final_submission_results/confusion_matrix.png)

---

## ğŸ‹ï¸ Training Evolution

The model was iteratively improved across **4 training versions**:

| Version | File | Resolution | Batch | Loss | Augmentation | Key Improvement |
|:-------:|------|:----------:|:-----:|------|:------------:|-----------------|
| V0 | `run_training.py` | 256 | 8 | CE | âŒ | Baseline |
| V1 | `local_train.py` | 256 | 6 | CE | âŒ | Local GPU tuning |
| V2 | `local_train_v2.py` | 256 | 6 | CE | âŒ | **Fixed mask ID mapping** (100â†’0, 200â†’1, â€¦) |
| V3 | `local_train_v3.py` | 256 | 6 | CE + Dice | âœ… Flip H/V | Augmentation, hybrid loss, cosine LR |
| V4 | `local_train_final.py` | 512 | 2 | CE + Dice | âœ… Flip H/V | High-res fine-tuning (LR=1e-5) |

### What Changed at Each Step

- **V0 â†’ V1**: Adjusted batch size to fit RTX 4050's 6 GB VRAM
- **V1 â†’ V2**: ğŸ› **Critical bug fix** â€” masks were being read as grayscale (`cv2.imread(path, 0)`), truncating raw IDs (100, 200, â€¦, 10000). Changed to `cv2.imread(path, -1)` and added `ID_MAPPING` to remap to 0â€“9
- **V2 â†’ V3**: Added horizontal/vertical flip augmentation, switched to hybrid CrossEntropy + Dice loss (massive IoU improvement for small classes like Logs), added cosine annealing LR scheduler
- **V3 â†’ V4**: Bumped resolution to 512Ã—512, lowered batch to 2, fine-tuned with LR=1e-5 from V3 weights

---

## ğŸ“‚ Project Structure

```
desert_hackathon/
â”œâ”€â”€ app.py                      # Streamlit web app for live inference
â”œâ”€â”€ best_model.pth              # Trained model weights (~93 MB)
â”œâ”€â”€ requirements.txt            # Python dependencies
â”œâ”€â”€ generate_readme_assets.py   # (Optional) Generate extra charts on a GPU machine
â”‚
â”œâ”€â”€ run_training.py             # V0 â€” Baseline training
â”œâ”€â”€ local_train.py              # V1 â€” Local GPU training
â”œâ”€â”€ local_train_v2.py           # V2 â€” Fixed mask ID mapping
â”œâ”€â”€ local_train_v3.py           # V3 â€” Augmentation + hybrid loss + scheduler
â”œâ”€â”€ local_train_final.py        # V4 â€” 512Ã—512 high-res fine-tuning
â”‚
â”œâ”€â”€ check_model.py              # Quick single-image visual check
â”œâ”€â”€ accurate_check.py           # Corrected mask reading validation
â”œâ”€â”€ check_iou.py                # Full validation set IoU computation
â”œâ”€â”€ check_split.py              # Train/val split ratio verification
â”œâ”€â”€ final_test.py               # Final eval: IoU + confusion matrix + visuals
â”‚
â”œâ”€â”€ final_submission_results/   # Pre-generated evaluation outputs
â”‚   â”œâ”€â”€ confusion_matrix.png
â”‚   â””â”€â”€ result_0..4.png
â”‚
â””â”€â”€ Offroad_Segmentation_Training_Dataset/  # Dataset (gitignored)
    â”œâ”€â”€ train/
    â”‚   â”œâ”€â”€ Color_Images/
    â”‚   â””â”€â”€ Segmentation/
    â””â”€â”€ val/
        â”œâ”€â”€ Color_Images/
        â””â”€â”€ Segmentation/
```

---

## ğŸš€ Getting Started

### Prerequisites

- Python 3.8+
- NVIDIA GPU with CUDA support (tested on RTX 4050 â€” 6 GB VRAM)

### Installation

```bash
git clone https://github.com/<YOUR_USERNAME>/desert_hackathon.git
cd desert_hackathon
pip install -r requirements.txt
```

### Dataset Setup

1. Download the **Offroad Segmentation Training Dataset** (provided by hackathon organizers).
2. Place it in the project root:
   ```
   desert_hackathon/
   â””â”€â”€ Offroad_Segmentation_Training_Dataset/
       â”œâ”€â”€ train/
       â”‚   â”œâ”€â”€ Color_Images/
       â”‚   â””â”€â”€ Segmentation/
       â””â”€â”€ val/
           â”œâ”€â”€ Color_Images/
           â””â”€â”€ Segmentation/
   ```

---

## ğŸ‹ï¸ Reproducing Training

```bash
# Step 1 â€” Baseline with corrected mask mapping
python local_train_v2.py

# Step 2 â€” Improve with augmentation + hybrid loss (resumes from V2)
python local_train_v3.py

# Step 3 â€” Fine-tune at 512Ã—512 (resumes from V3)
python local_train_final.py
```

---

## ğŸ§ª Evaluation

```bash
# Quick visual check on a random validation image
python check_model.py

# Accurate visual check with correct mask reading
python accurate_check.py

# Per-class IoU on the full validation set
python check_iou.py

# Full evaluation: IoU + confusion matrix + 5 visual results
python final_test.py

# Verify train/val split ratio
python check_split.py

# (Optional, requires GPU) Generate bar charts & sample prediction grids
python generate_readme_assets.py
```

---

## ğŸŒ Web App

Launch the interactive Streamlit demo:

```bash
streamlit run app.py
```

**Features:**
- ğŸ“¤ Upload any terrain image for real-time segmentation
- ğŸ–¼ï¸ Side-by-side original vs. AI perception view
- ğŸ“ˆ Live confidence score (softmax-based)
- ğŸ“Š Pre-computed baseline metrics dashboard
- ğŸ” Expandable detailed per-class IoU breakdown
- ğŸ—ºï¸ Color-coded terrain legend

---

## ğŸ”‘ Key Technical Decisions

### 1. Raw Mask Reading
Segmentation masks encode class IDs as raw pixel values (100, 200, â€¦, 10000). Reading as `cv2.imread(path, 0)` (grayscale) truncates values above 255, causing incorrect labels. Using `cv2.imread(path, -1)` reads unchanged values and preserves the original IDs.

### 2. Hybrid CE + Dice Loss
CrossEntropy alone struggles with underrepresented classes (Logs, Rocks, Ground Clutter). Dice loss focuses on per-class overlap and significantly boosted IoU for these minority classes.

### 3. Progressive Training
Instead of training at 512Ã—512 from scratch (GPU memory-prohibitive at batch sizes needed), we first converge at 256Ã—256 and then fine-tune at 512Ã—512 with a very low learning rate. Faster convergence, lower memory usage.

### 4. Default Class Fallback
Unknown / unmapped pixel values in masks are assigned to class 8 (Landscape) as a safe default to prevent training crashes from out-of-range class indices.

---

## ğŸ‘¥ Team

| Name | Role |
|------|------|
| `Dhruv Bajpai` | `Team Lead` |
| `Samarth Shukla` | `Backend` |
| `Kshitij Trivedi` | `Frontend` |

---

## ğŸ“„ License

This project was developed for the **Startathon Desert Hackathon**. Please check with the organizers for dataset licensing and usage terms.

---

## ğŸ™ Acknowledgments

- [segmentation-models-pytorch](https://github.com/qubvel/segmentation_models.pytorch) by Pavel Iakubovskii
- [Streamlit](https://streamlit.io/) for the interactive demo framework
- Hackathon organizers for the Offroad Segmentation dataset
